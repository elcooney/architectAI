{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9cb5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using UnstructuredPDFLoader which can handle images in PDFs\n",
    "# from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# OR using DirectoryLoader to handle multiple files\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders.unstructured import UnstructuredFileLoader\n",
    "\n",
    "# For direct OCR with images, use Python's pytesseract with a custom document loader\n",
    "from langchain_core.documents import Document\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this code definitely works\n",
    "# def load_image_with_ocr(file_path):\n",
    "#     try:\n",
    "#         # Use pytesseract to extract text from image\n",
    "#         img = Image.open(file_path)\n",
    "#         text = pytesseract.image_to_string(img)\n",
    "#         # Create a LangChain document\n",
    "#         return Document(\n",
    "#             page_content=text,\n",
    "#             metadata={\"source\": file_path}\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {file_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Function to process a directory of images\n",
    "# def process_image_directory(directory_path):\n",
    "#     documents = []\n",
    "#     if os.path.exists(directory_path):\n",
    "#         for file in os.listdir(directory_path):\n",
    "#             if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "#                 file_path = os.path.join(directory_path, file)\n",
    "#                 doc = load_image_with_ocr(file_path)\n",
    "#                 if doc:\n",
    "#                     documents.append(doc)\n",
    "#                     print(f\"Successfully loaded image: {file_path}\")\n",
    "#     return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b18be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a directory of images\n",
    "def process_image_directory(directory_path):\n",
    "    documents = []\n",
    "    if os.path.exists(directory_path):\n",
    "        for file in os.listdir(directory_path):\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(directory_path, file)\n",
    "                try:\n",
    "                    # Use pytesseract to extract text from image\n",
    "                    img = Image.open(file_path)\n",
    "                    text = pytesseract.image_to_string(img)\n",
    "                    # Create a LangChain document\n",
    "                    doc = Document(\n",
    "                        page_content=text,\n",
    "                        metadata={\"source\": file_path}\n",
    "                    )\n",
    "                # Handle any exceptions that may occur during image processing\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "                    return None\n",
    "                # If the document was created successfully, add it to the list\n",
    "                if doc:\n",
    "                    documents.append(doc)\n",
    "                    print(f\"Successfully loaded image: {file_path}\")\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78131259",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3c6ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1105.1.1_publicentrancewithpoweroperateddoor.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1106.2_accessibleparkingspaces.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1108.6.1.1_accessibledwellingwunitsandsleepingunits.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1109.2.2.1_accessiblewheelchairspaces.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1109.2.7.1_receiversforassistivelisteningsystems.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1109.3_accessibleselfservicestoragefacilities.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1110.13.1_accessiblecheckoutaisles.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_1111.4.9.1_boatslips.png\n",
      "Successfully loaded image: C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\\data_tables\\table_907.5.2.3.2_visiblealarms.png\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "image_folder = os.path.join(base_path, \"data_tables\")\n",
    "documents = process_image_directory(image_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
