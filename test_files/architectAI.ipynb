{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f4563b",
   "metadata": {},
   "source": [
    "# File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to work in: virtual environment based on \"requirements.txt\"\n",
    "# create secrets location!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50981a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredImageLoader #provided via copilot\n",
    "from langchain_community.document_loaders import CSVLoader #provided via copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bdedddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the API key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ff7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set folder path(s) for data\n",
    "\n",
    "CSV_FOLDER = \"data/data_csv\"\n",
    "TABLE_IMAGES_FOLDER = \"data/data_tables\"\n",
    "PDF_FOLDER = \"data/data_PDFs\"\n",
    "\n",
    "# data = pd.read_csv(\"data/ADA Spreadsheet - 2021 International Existing Building Code - Sheet1.csv\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ee8a3",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0826ad8",
   "metadata": {},
   "source": [
    "### processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attemping to load CSV file: C:/Users/elcoo/Documents/python/ArchitectAI/data/data_csv\\ADASpreadsheet.csv\n",
      "Successfully loaded ADASpreadsheet.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter_Number</th>\n",
       "      <th>Chapter_Name</th>\n",
       "      <th>Section_Number</th>\n",
       "      <th>Section_Name</th>\n",
       "      <th>Section_Note</th>\n",
       "      <th>Subsection_Number</th>\n",
       "      <th>Subsection_Name</th>\n",
       "      <th>Subsection_Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Appendix E</td>\n",
       "      <td>Supplementary Accessibility Requirements</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The provisions contained in this appendix are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Appendix E</td>\n",
       "      <td>Supplementary Accessibility Requirements</td>\n",
       "      <td>E101</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E101.1</td>\n",
       "      <td>Scope</td>\n",
       "      <td>The provisions of this appendix shall control ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Appendix E</td>\n",
       "      <td>Supplementary Accessibility Requirements</td>\n",
       "      <td>E101</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E101.2</td>\n",
       "      <td>Design</td>\n",
       "      <td>Technical requirements for items herein shall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Appendix E</td>\n",
       "      <td>Supplementary Accessibility Requirements</td>\n",
       "      <td>E102</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E102.1</td>\n",
       "      <td>General</td>\n",
       "      <td>The following words and terms shall, for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Appendix E</td>\n",
       "      <td>Supplementary Accessibility Requirements</td>\n",
       "      <td>E103</td>\n",
       "      <td>Accessible Route</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E103.1</td>\n",
       "      <td>Raised platforms</td>\n",
       "      <td>In banquet rooms or spaces where a head table ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chapter_Number                              Chapter_Name Section_Number  \\\n",
       "0     Appendix E  Supplementary Accessibility Requirements            NaN   \n",
       "1     Appendix E  Supplementary Accessibility Requirements           E101   \n",
       "2     Appendix E  Supplementary Accessibility Requirements           E101   \n",
       "3     Appendix E  Supplementary Accessibility Requirements           E102   \n",
       "4     Appendix E  Supplementary Accessibility Requirements           E103   \n",
       "\n",
       "       Section_Name                                       Section_Note  \\\n",
       "0               NaN  The provisions contained in this appendix are ...   \n",
       "1           General                                                NaN   \n",
       "2           General                                                NaN   \n",
       "3       Definitions                                                NaN   \n",
       "4  Accessible Route                                                NaN   \n",
       "\n",
       "  Subsection_Number   Subsection_Name  \\\n",
       "0               NaN               NaN   \n",
       "1            E101.1             Scope   \n",
       "2            E101.2            Design   \n",
       "3            E102.1           General   \n",
       "4            E103.1  Raised platforms   \n",
       "\n",
       "                                     Subsection_Note  \n",
       "0                                                NaN  \n",
       "1  The provisions of this appendix shall control ...  \n",
       "2  Technical requirements for items herein shall ...  \n",
       "3  The following words and terms shall, for the p...  \n",
       "4  In banquet rooms or spaces where a head table ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to load and process CSV files\n",
    "CSV_FOLDER_test = \"C:/Users/elcoo/Documents/python/ArchitectAI/data/data_csv\"\n",
    "\n",
    "def load_and_process_csv():\n",
    "    try:\n",
    "\n",
    "        # ensure path exists\n",
    "        if not os.path.exists(CSV_FOLDER_test):\n",
    "            print(f\"Directory ont found: {CSV_FOLDER_test}\")\n",
    "            return None\n",
    "        \n",
    "        # create list of CSV files in the directory\n",
    "        csv_files = [f for f in os.listdir(CSV_FOLDER_test) if f.endswith('.csv')]\n",
    "        if not csv_files:\n",
    "            print(f\"No CSV files found in {CSV_FOLDER_test}\")\n",
    "            return None\n",
    "\n",
    "        # load each CSV file into a DataFrame and combine them\n",
    "        dataframes = []\n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(CSV_FOLDER_test, csv_file)\n",
    "            print(f\"Attemping to load CSV file: {file_path}\")\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                dataframes.append(df)\n",
    "                print(f\"Successfully loaded {csv_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {csv_file}: {str(e)}\")\n",
    "            \n",
    "            # use langchain CSVLoader to load the file ## NOT WORKING YET\n",
    "            # loader = CSVLoader(file_path, csv_args={'delimiter': '|'})\n",
    "            # data = loader.load()\n",
    "            # dataframes.append(data)\n",
    "\n",
    "        if not dataframes:\n",
    "            print(f\"No CSV files found in {CSV_FOLDER_test}\")\n",
    "            return None\n",
    "\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CSV processing error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "df = load_and_process_csv()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa759d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "\n",
    "# Function to load and process CSV files\n",
    "def load_and_process_csv():\n",
    "    try:\n",
    "        csv_files = [f for f in os.listdir(CSV_FOLDER) if f.endswith('.csv')]\n",
    "        if not csv_files:\n",
    "            st.error(f\"No CSV files found in {CSV_FOLDER}\")\n",
    "            return None\n",
    "\n",
    "        dataframes = []\n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(CSV_FOLDER, csv_file)\n",
    "            loader = CSVLoader(file_path)\n",
    "            df = loader.load()\n",
    "            dataframes.append(df)\n",
    "\n",
    "        if not dataframes:\n",
    "            st.error(f\"No CSV files found in {CSV_FOLDER}\")\n",
    "            return None\n",
    "\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"CSV processing error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and process images   \n",
    "def load_and_process_images():\n",
    "    try:\n",
    "        image_files = [f for f in os.listdir(TABLE_IMAGES_FOLDER) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if not image_files:\n",
    "            st.error(f\"No image files found in {TABLE_IMAGES_FOLDER}\")\n",
    "            return None\n",
    "\n",
    "        documents = []\n",
    "        for image_file in image_files:\n",
    "            file_path = os.path.join(TABLE_IMAGES_FOLDER, image_file)\n",
    "            loader = UnstructuredImageLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "        if not documents:\n",
    "            st.error(f\"No documents loaded from images in {TABLE_IMAGES_FOLDER}\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"Image processing error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to load and process PDF files\n",
    "def load_and_process_pdfs():\n",
    "    try:\n",
    "        pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith('.pdf')]\n",
    "        if not pdf_files:\n",
    "            st.error(f\"No PDF files found in {PDF_FOLDER}\")\n",
    "            return None\n",
    "        \n",
    "        documents = []\n",
    "        for filename in os.listdir(PDF_FOLDER):\n",
    "            if filename.endswith('.pdf'):\n",
    "                file_path = os.path.join(PDF_FOLDER, filename)\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "\n",
    "        if not documents:\n",
    "            st.error(f\"No PDF files found in {PDF_FOLDER}\")\n",
    "            return None\n",
    "\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        st.error(f\"PDF processing error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d4a07",
   "metadata": {},
   "source": [
    "### chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7647ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "def architect_AI(documents: List, model_name: str = 'gpt-4', \n",
    "                  chunk_size: int = 1000, chunk_overlap: int = 200,\n",
    "                  persist_dir: str = 'db') -> Optional[ConversationalRetrievalChain]:\n",
    "    try:\n",
    "        # Check if documents are provided\n",
    "        if not documents:\n",
    "            st.error(\"No documents provided for processing.\")\n",
    "            return None\n",
    "\n",
    "        # Split the documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, \n",
    "            chunk_overlap=chunk_overlap)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Create a vector store from the chunks\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vector_store = Chroma.from_documents(\n",
    "            chunks, \n",
    "            embedding=embeddings, \n",
    "            persist_directory=persist_dir)\n",
    "\n",
    "        # set up retrieval chain\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "        # set up LLM\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0.7)\n",
    "\n",
    "        \n",
    "        # set up memory for the conversation\n",
    "        memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True,\n",
    "            output_key=\"answer\"  # Specify the output key for memory storage\n",
    "        )\n",
    "\n",
    "        # Create conversation chain\n",
    "        crc = ConversationalRetrievalChain.from_llm(\n",
    "            llm,\n",
    "            retriever,\n",
    "            memory=memory,\n",
    "            return_source_documents=True,\n",
    "            output_key=\"answer\"  # Specify the output key for the chain\n",
    "        )\n",
    "        return crc\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d7618",
   "metadata": {},
   "source": [
    "### streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a8246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # title and welcome message\n",
    "    st.title(\"Architect AI\")\n",
    "    st.write(\"Welcome to the Architect AI application!\")\n",
    "\n",
    "\n",
    "    # Load and process documents\n",
    "    csv_docs = load_and_process_csv()\n",
    "    image_docs = load_and_process_images()\n",
    "    pdf_docs = load_and_process_pdfs()\n",
    "\n",
    "    # combine all documents into a single list\n",
    "    documents = []\n",
    "    for docs in [csv_docs, image_docs, pdf_docs]:\n",
    "        if docs is not None:\n",
    "            documents.extend(docs)\n",
    "   \n",
    "    # Return error if no documents were loaded\n",
    "    if not documents:\n",
    "        st.error(\"No documents loaded from any source.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Set up the AI chatbot\n",
    "    chatbot = architect_AI(documents)\n",
    "\n",
    "    # Check if the AI model was set up successfully\n",
    "    if not chatbot:\n",
    "        st.error(\"Failed to set up AI chatbot.\")\n",
    "        return\n",
    "\n",
    "    # Chat interface\n",
    "    if chatbot: \n",
    "        st.subheader(\"Ask ArchitectAI anything about the ADA and code documents you've uploaded.\")\n",
    "        user_query = st.text_input(\"Enter your question:\")\n",
    "\n",
    "        if user_query and st.button(\"Submit\"):\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                response = chatbot({\"question\": user_query})\n",
    "                st.write(\"Answer:\", response['answer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d35bdc",
   "metadata": {},
   "source": [
    "## Run Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af70902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 16:05:41.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-31 16:05:41.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
