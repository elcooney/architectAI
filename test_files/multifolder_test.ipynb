{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7827bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DataFrameLoader, PyPDFLoader, UnstructuredFileLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "# For direct OCR with images, use Python's pytesseract with a custom document loader\n",
    "from langchain_core.documents import Document\n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load the OpenAI API key from environment variables   \n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c77658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(base_path):\n",
    "    documents = []\n",
    "\n",
    "    #load CSV files as dataframe\n",
    "    csv_folder = os.path.join(base_path, \"data_csv\")\n",
    "    if os.path.exists(csv_folder):\n",
    "        for file in os.listdir(csv_folder):\n",
    "            if file.endswith(\".csv\"):\n",
    "                try: \n",
    "                    df = pd.read_csv(os.path.join(csv_folder, file))\n",
    "                    clean_df = df.fillna(\"See section note\")\n",
    "                    df_loader = DataFrameLoader(clean_df, page_content_column=\"Subsection_Note\")\n",
    "                    documents.extend(df_loader.load())\n",
    "                    print(f\"Successfully loaded CSV: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "    # Load PDF files\n",
    "    pdf_folder = os.path.join(base_path, \"data_PDFs\")\n",
    "    if os.path.exists(pdf_folder):\n",
    "        for file in os.listdir(pdf_folder):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                try:\n",
    "                    pdf_loader = PyPDFLoader(os.path.join(pdf_folder, file))\n",
    "                    documents.extend(pdf_loader.load())\n",
    "                    print(f\"Successfully loaded PDF: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file}: {e}\")\n",
    "######################################################################################\n",
    "\n",
    "    # # Load image files\n",
    "    image_folder = os.path.join(base_path, \"data_tables\")\n",
    "    if os.path.exists(image_folder):\n",
    "        for file in os.listdir(image_folder):\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(image_folder, file)\n",
    "                try:\n",
    "                    # Use pytesseract to extract text from image\n",
    "                    img = Image.open(file_path)\n",
    "                    text = pytesseract.image_to_string(img)\n",
    "                    # Create a LangChain document\n",
    "                    doc = Document(\n",
    "                        page_content=text,\n",
    "                        metadata={\"source\": file_path}\n",
    "                    )\n",
    "                # Handle any exceptions that may occur during image processing\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "                    return None\n",
    "                # If the document was created successfully, add it to the list\n",
    "                if doc:\n",
    "                    documents.append(doc)\n",
    "                    print(f\"Successfully loaded image: {file_path}\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770285c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(documents):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    vector_store = Chroma.from_documents(documents, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f719ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv as dataframe and pdf documents. \n",
    "base_path = r\"C:\\Users\\elcoo\\Documents\\python\\ArchitectAI\\data\"\n",
    "documents = load_documents(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_documents(documents)\n",
    "vector_store = create_vector_store(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ec301",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=openai_api_key, model='gpt-4', temperature=0.7)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\":40})\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"  # Specify the output key for memory storage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\"  # Specify the output key for the chain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to handle chat interactions\n",
    "def chat_with_documents():\n",
    "    print(\"Welcome to the Document Chatbot! Type 'exit' to end the conversation.\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"\\nYour question: \")\n",
    "        \n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Thank you for using the Document Chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Get response from the chain\n",
    "        response = crc.invoke({\"question\": user_query})\n",
    "        \n",
    "        # Print the response\n",
    "        print(\"\\nChatbot:\", response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_documents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
